{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cb1e608-4d53-4057-8023-09323a947f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "735dbd3b-b827-400b-993b-b27b5d751564",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run input_data_check.ipynb\n",
    "%run pii_detector.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4814d7b5-c2b5-4a99-b72d-6c1f026990d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from guardrails import Guard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a1d19f8-2d2e-4a18-a213-c815a4205e21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: ./Embedding_Model/all_mini_embed_model/models--sentence-transformers--all-MiniLM-L6-v2/snapshots/c9745ed1d9f207416be6d2e6f8de32d1f16199bf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8d0faab4e447438d853ef6374b4b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb325beafe84ca59468af3572af2730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077a8d7030224ad9927139cef452831d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1629ea1c404553b8674553961f2bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b0bd70e8184d9c87d841d49fd921dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c0ffb72540f4aedb2125dd1cf0a8710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43730f42ce824320871bb595ba9539e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983872962ce941eeae5ac61074a5c218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e96a23710c44493bbc71b65611adb1fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea2b5bafccf499b91cdf85169f4b386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d0d1f0faab4481992b9d0ca3679f5af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5d556a42b0946519cff8ea492bd816a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ebe7a1c5bcd4d08bf320f57a008b65f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfc4c402fe64ae98c6ac0bfbcc141a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45053e10fd64177a35e78da63ccdcdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b56046a301c146d3a919b21468027b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab7fc93c88e49e98a445bc39cc188c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ba0e1b5f01463dbb65de68154cc6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0097ac92804f4c57a411a834b3971ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e395252741471e946b7ac712de6d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6728f387ade4491d8cf1b5f2eabc0c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06d5553ad4cf4e468cac1501cca16319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3bb7b5cbd04052b548dd0440c1fdd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299eb58f20604cf8bf4beb419caa9576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a89abad2e0d47959b708ecad7e6080b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a073ed07949e439cbc44631eba164f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Guard(id='WINRWE', name='gr-WINRWE', description=None, validators=[ValidatorReference(id='AdvancedPIIValidator', on='$', on_fail='exception', args=None, kwargs={})], output_schema=ModelSchema(definitions=None, dependencies=None, anchor=None, ref=None, dynamic_ref=None, dynamic_anchor=None, vocabulary=None, comment=None, defs=None, prefix_items=None, items=None, contains=None, additional_properties=None, properties=None, pattern_properties=None, dependent_schemas=None, property_names=None, var_if=None, then=None, var_else=None, all_of=None, any_of=None, one_of=None, var_not=None, unevaluated_items=None, unevaluated_properties=None, multiple_of=None, maximum=None, exclusive_maximum=None, minimum=None, exclusive_minimum=None, max_length=None, min_length=None, pattern=None, max_items=None, min_items=None, unique_items=None, max_contains=None, min_contains=None, max_properties=None, min_properties=None, required=None, dependent_required=None, const=None, enum=None, type=ValidationType(anyof_schema_1_validator=None, anyof_schema_2_validator=None, actual_instance=<SimpleTypes.STRING: 'string'>, any_of_schemas={'SimpleTypes', 'List[SimpleTypes]'}), title=None, description=None, default=None, deprecated=None, read_only=None, write_only=None, examples=None, format=None, content_media_type=None, content_encoding=None, content_schema=None), history=[])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matcher = AdvancedQueryMatcher()\n",
    "\n",
    "guard = Guard()\n",
    "guard.use_many(AdvancedPIIValidator())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9306ce-2858-4791-ba22-afc4b175a40d",
   "metadata": {},
   "source": [
    "The below function serves as the main entry point for processing a user query comprehensively. It analyzes the query for similarity against predefined risky topics and sentences, evaluates risk levels, and provides both a detailed analysis and a category-wise breakdown. Based on the results, it determines whether the query is safe, high-risk, or medium-risk. For safe queries below the low-risk threshold, it marks them as approved. For high-risk queries, it blocks the request with an explanatory message. Medium-risk queries receive a cautious response, offering general educational guidance while maintaining safety. The function returns a structured response dictionary containing the query, analysis, category breakdown, status, and response message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ee14be5-893b-4c1b-be17-19a09e721d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query_comprehensive(query: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Main function to process a query with comprehensive analysis and response.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Perform full query analysis\n",
    "    analysis = matcher.analyze_query(query)\n",
    "    \n",
    "    # Get detailed breakdown by category\n",
    "    category_breakdown = matcher.get_category_breakdown(query)\n",
    "    \n",
    "    # Initialize response dictionary\n",
    "    response = {\n",
    "        'query': query,\n",
    "        'analysis': analysis,\n",
    "        'category_breakdown': category_breakdown,\n",
    "        'response': ''\n",
    "    }\n",
    "\n",
    "    # Case 1: Query is safe and similarity is below low-risk threshold\n",
    "    if analysis.is_safe and analysis.highest_similarity < matcher.risk_thresholds['low_risk']:\n",
    "        response['response'] = 'SAFE'\n",
    "        response['status'] = 'approved'\n",
    "    \n",
    "    # Case 2: Query has high-risk similarity\n",
    "    else:        \n",
    "        if analysis.highest_similarity >= matcher.risk_thresholds['high_risk']:\n",
    "            response['response'] = (\n",
    "                f\"I cannot assist with this request as it relates to {analysis.primary_category.replace('_', ' ')} \"\n",
    "                f\"content. Please ensure your queries are appropriate and safe.\"\n",
    "            )\n",
    "            response['status'] = 'blocked'\n",
    "        \n",
    "        # Case 3: Medium-risk query - cautious guidance\n",
    "        else:\n",
    "            response['response'] = (\n",
    "                f\"I notice your query may relate to {analysis.primary_category.replace('_', ' ')} topics. \"\n",
    "                f\"I can provide general, educational information while ensuring safety and appropriateness.\"\n",
    "            )\n",
    "            response['status'] = 'cautious'\n",
    "    \n",
    "    # Return final structured response\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df7620e-492d-45ce-9e9a-965dc80c03d0",
   "metadata": {},
   "source": [
    "The below function processes a single user query by first running a comprehensive matcher (process_query_comprehensive) to obtain classification, analysis, and a suggested response. It then branches on the matcher's returned status: if BLOCKED, it returns a blocked response with a small analysis summary; if CAUTIOUS, it logs/prints the matcher result and returns a cautious response summary (intentionally avoiding any further guard validation); if APPROVED, it runs a guard validation (guard.validate) and records whether the guard passed or failed (calling check_guardrail_result to amend the matcher result on failure). Any unexpected exception during processing returns an \"error\" response with the exception text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a53537f0-39ae-40d1-9eb7-39fc04d37045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query: str) -> Dict[str, Any]:\n",
    "    # Define function signature: accepts a query string and returns a result dictionary\n",
    "    \"\"\"Process a single query with matcher and Guard validation.\"\"\"\n",
    "    # Docstring: short description of the function purpose\n",
    "\n",
    "    try:\n",
    "        # Start a try block to catch unexpected runtime errors during processing\n",
    "        matcher_result = process_query_comprehensive(query)\n",
    "        # Call the comprehensive matcher to analyze the query; expect a dict with keys like 'status', 'analysis', 'response'\n",
    "        \n",
    "\n",
    "        # --- BLOCKED branch ---\n",
    "        if matcher_result.get(\"status\", \"\").upper() == \"BLOCKED\":\n",
    "            # Normalize status string and check if result indicates a blocked query\n",
    "            analysis = matcher_result.get(\"analysis\")\n",
    "            # Extract the analysis object from the matcher result (likely a QueryAnalysis object)\n",
    "\n",
    "            return {\n",
    "                # Return a dictionary immediately for blocked queries\n",
    "                \"query\": query,  # Echo the original query\n",
    "                \"status\": \"blocked\",  # Human-friendly status\n",
    "                \"analysis\": {\n",
    "                    # Provide a compact analysis summary for callers\n",
    "                    \"is_safe\": analysis.is_safe,\n",
    "                    \"risk_assessment\": analysis.risk_assessment,\n",
    "                    \"flagged_categories\": analysis.flagged_categories\n",
    "                },\n",
    "                \"response\": matcher_result.get(\"response\", \"\")\n",
    "                # Include the text response from the matcher if present (empty string fallback)\n",
    "            }\n",
    "\n",
    "        # --- CAUTIOUS branch ---\n",
    "        elif matcher_result.get(\"status\", \"\").upper() == \"CAUTIOUS\":\n",
    "            # Check if the matcher classified the query as cautious\n",
    "            # PEVENTING GUARDRAIL CHECK IF DETECTED HERE\n",
    "            analysis = matcher_result.get(\"analysis\")\n",
    "            # Extract analysis object for inclusion in the returned summar\n",
    "\n",
    "            return {\n",
    "                # Return a cautious response summary to caller\n",
    "                \"query\": query,  # Echo original query\n",
    "                \"status\": \"cautious\",  # Human-friendly status\n",
    "                \"analysis\": {\n",
    "                    # Provide compact analysis summary\n",
    "                    \"is_safe\": analysis.is_safe,\n",
    "                    \"risk_assessment\": analysis.risk_assessment,\n",
    "                    \"flagged_categories\": analysis.flagged_categories\n",
    "                },\n",
    "                \"response\": matcher_result.get(\"response\", \"\")\n",
    "                # Include matcher's response text (or empty string)\n",
    "            }\n",
    "\n",
    "        # --- APPROVED branch ---\n",
    "        elif matcher_result.get(\"status\", \"\").upper() == \"APPROVED\":\n",
    "            # If matcher approves the request, perform guardrail validation\n",
    "            try:\n",
    "                guard.validate(query)\n",
    "                # Call guard.validate to perform policy/guardrail checks on the query; may raise an exception on failure\n",
    "                matcher_result[\"guard_validation\"] = \"passed\"\n",
    "                # If no exception raised, mark guard validation as passed in the matcher_result dict\n",
    "            except Exception as e:\n",
    "                # If guard validation raised an exception, capture it here\n",
    "                matcher_result[\"guard_validation\"] = f\"failed - {str(e)}\"\n",
    "                # Annotate matcher_result with the failure reason\n",
    "                matcher_result = check_guardrail_result(matcher_result)\n",
    "\n",
    "                # Optionally mutate/augment matcher_result via check_guardrail_result to reflect guard findings\n",
    "\n",
    "            return matcher_result\n",
    "            # Return the (possibly updated) matcher_result for approved queries after guard validation\n",
    "\n",
    "    except Exception as e:\n",
    "        # Top-level exception handler: catch any unexpected error that occurred above\n",
    "        return {\n",
    "            # Return a standardized error response\n",
    "            \"query\": query,  # Echo original query\n",
    "            \"status\": \"error\",  # Status indicating an internal error\n",
    "            \"error\": str(e)  # Stringified exception message for debugging\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5df40032-903e-4d88-9b22-f4e661cc8c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'hello 9876543421', 'status': 'rejected', 'reason': 'failed - validation failed for field with errors: pii risk detected: phone number detected; bank account information detected', 'message': 'Query rejected due to guardrail validation failure.'}\n"
     ]
    }
   ],
   "source": [
    "result = process_query_batch([\"hello 9876543421\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ef80e85c-324b-4da8-a4af-9bebc3ac6a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'query': 'hello 9876543421', 'status': 'not_completed', 'reason': {'status': 'rejected', 'guard_validation': '', 'risk_assessment': 'not available'}, 'message': 'Query not safe to process, execution blocked.'}]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03b3920-93f7-43a8-aa42-d373d1c94e4e",
   "metadata": {},
   "source": [
    "The function check_guardrail_result ensures that results returned after processing a query correctly reflect any guardrail validation outcomes.\n",
    "* If the guard validation failed, the query is immediately marked as rejected with a rejection reason.\n",
    "* If the query’s status is already blocked, the blocked result (including analysis) is returned as-is.\n",
    "* Otherwise, the query is considered approved, and the result is returned with a passed guard validation (default if not explicitly provided).\n",
    "\n",
    "This acts as a post-processor to normalize the query result and enforce guardrail decisions consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c5011c10-f644-465c-bf57-d95c6cb201ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_guardrail_result(result: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Check the processed query result for guardrail failures.\"\"\"\n",
    "    \n",
    "    \n",
    "    # Extract the current status of the result (default \"unknown\" if missing).\n",
    "    status = result.get(\"status\", \"unknown\").lower()\n",
    "    \n",
    "    # Extract the guard validation result (default empty string).\n",
    "    # Convert to lowercase for consistent comparison.\n",
    "    guard_validation = result.get(\"guard_validation\", \"\").lower()\n",
    "    \n",
    "\n",
    "    # --- Case 1: Guardrail validation failed ---\n",
    "    if \"failed\" in guard_validation:\n",
    "        # If guard validation indicates failure, override the result.\n",
    "        return {\n",
    "            \"query\": result.get(\"query\"),  # Original query text\n",
    "            \"status\": \"rejected\",  # Explicit rejection status\n",
    "            \"reason\": guard_validation,  # Store failure reason for debugging\n",
    "            \"message\": \"Query rejected due to guardrail validation failure.\"\n",
    "            # User-facing message explaining rejection\n",
    "        }\n",
    "\n",
    "    # --- Case 2: Query was BLOCKED earlier ---\n",
    "    if status == \"blocked\":\n",
    "        # Preserve the original blocked status, analysis, and response\n",
    "        return {\n",
    "            \"query\": result.get(\"query\"),     # Original query\n",
    "            \"status\": \"blocked\",              # Keep blocked status\n",
    "            \"analysis\": result.get(\"analysis\"),  # Risk/analysis info from matcher\n",
    "            \"response\": result.get(\"response\")   # Response provided by matcher\n",
    "        }\n",
    "\n",
    "    # --- Case 3: Otherwise, treat as APPROVED ---\n",
    "    return {\n",
    "        \"query\": result.get(\"query\"),  # Original query\n",
    "        \"status\": \"approved\",  # Mark as approved since no failures/blocking found\n",
    "        \"response\": result.get(\"response\", \"\"),  # Safe response (fallback empty string)\n",
    "        \"guard_validation\": guard_validation or \"passed\"\n",
    "        # If guard_validation not explicitly set, assume \"passed\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db501992-83e8-45a2-860f-3d6f08b13179",
   "metadata": {},
   "source": [
    "The function call_model_safely provides a safety wrapper for calling a language model (in this case, Ollama with llama3:8b).\n",
    "* It ensures that the model is always prompted with safety instructions (system message) to avoid unsafe responses.\n",
    "* It tries to generate a response from the model while catching any errors.\n",
    "* If the model call fails for any reason (e.g., API issue, network problem), it logs the error and returns a polite fallback message instead of crashing.\n",
    "\n",
    "This function guarantees both safe prompting and robust error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "782289b2-a6c9-4776-a116-60fc9eec72ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model_safely(query: str) -> str:\n",
    "    \"\"\"Call the language model with safety checks.\"\"\"\n",
    "    try:\n",
    "        # Build conversation history for the model\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",   # System prompt sets rules for model behavior\n",
    "                \"content\": (\n",
    "                    \"You are a helpful and safe assistant. \"\n",
    "                    \"Answer only valid, safe, and appropriate questions. \"\n",
    "                    \"If the query involves harmful, illegal, or inappropriate content, \"\n",
    "                    \"politely decline and explain why you cannot help. \"\n",
    "                    \"Be clear, concise, and professional.\"\n",
    "                )\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",    # Actual user query\n",
    "                \"content\": query\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Call Ollama model with structured messages\n",
    "        response = ollama.chat(\n",
    "            model=\"llama3:8b\",     # Chosen model\n",
    "            messages=messages,     # Messages (system + user)\n",
    "            options={\"temperature\": 0.0}  # Deterministic output for safety\n",
    "        )\n",
    "        \n",
    "        # Extract model's generated text from response object\n",
    "        return response['message']['content']\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Return a polite fallback message to the user\n",
    "        return \"I apologize, but I'm unable to process your request at this time.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e776f5-e5ad-42db-bfb4-6b98f6a76292",
   "metadata": {},
   "source": [
    "The function execute_if_safe is a gatekeeper for executing the model call.\n",
    "* It takes in a result dictionary (likely produced by your query matcher + guard system).\n",
    "* It checks if the query is safe, approved, and passed guard validation before allowing execution.\n",
    "* If all checks pass → it calls call_model_safely to get the model response.\n",
    "* If checks fail → it blocks execution and returns a structured reason explaining why it was not completed.\n",
    "\n",
    "This ensures strict enforcement of safety checks before hitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0a60e4c0-4aae-47a3-b4a5-7c1078af2dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_if_safe(result: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Execute call_model_safely only if the response is safe and guard validation passed.\n",
    "    Otherwise return reason for not completing.\"\"\"\n",
    "    \n",
    "    # Extract key fields from the result dict\n",
    "    analysis = result.get(\"analysis\")                        # Analysis object/dict with risk info\n",
    "    status = result.get(\"status\", \"\").lower()               # Status string: approved / blocked / cautious / error\n",
    "\n",
    "    if 'reason' in result:\n",
    "        guard_validation = result['reason']\n",
    "    else:\n",
    "        guard_validation = result.get(\"guard_validation\", \"blocked by safety check\").lower()  # Guard check result: passed / failed\n",
    "    \n",
    "\n",
    "    # Extract risk assessment text if analysis is present\n",
    "    if isinstance(analysis, dict):\n",
    "        risk_assessment = analysis.get(\"risk_assessment\", \"not available\").lower()\n",
    "    elif hasattr(analysis, \"risk_assessment\"):\n",
    "        risk_assessment = getattr(analysis, \"risk_assessment\", \"not available\").lower()\n",
    "    else:\n",
    "        risk_assessment = \"not available\"\n",
    "\n",
    "    \n",
    "    # Condition: only allow execution if ALL checks are safe\n",
    "    if (\n",
    "        analysis                               # Analysis must exist\n",
    "        and getattr(analysis, \"is_safe\", False)  # Analysis must say it's safe\n",
    "        and status == \"approved\"                 # Must be explicitly approved\n",
    "        and guard_validation == \"passed\"         # Guard check must pass\n",
    "    ):\n",
    "        # Safe to execute → call the model\n",
    "        return {\n",
    "            \"query\": result.get(\"query\"),\n",
    "            \"status\": \"completed\",\n",
    "            \"response\": call_model_safely(result[\"query\"])  # Call model safely\n",
    "        }\n",
    "    else:\n",
    "        # Block execution → return structured reason\n",
    "        return {\n",
    "            \"query\": result.get(\"query\"),\n",
    "            \"status\": \"not_completed\",   # Explicitly mark as blocked\n",
    "            \"reason\": {\n",
    "                \"status\": status,                   # Whether blocked/cautious/error\n",
    "                \"guard_validation\": guard_validation,  # Guard failure reason\n",
    "                \"risk_assessment\": risk_assessment     # Why it was flagged\n",
    "            },\n",
    "            \"message\": \"Query not safe to process, execution blocked.\"\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "67a9a25f-f6e0-43ac-920a-9b70440e5d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query_batch(queries: List[str]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Process multiple queries sequentially with matcher and Guard validation.\"\"\"\n",
    "    start_time = time.time()\n",
    "    results = [process_query(query) for query in queries]\n",
    "    model_call = [execute_if_safe(response) for response in results]\n",
    "    end_time = time.time()\n",
    "    #logger.info(f\"Processed {len(queries)} queries in {end_time - start_time:.2f} seconds\")\n",
    "    return model_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c4cd2f54-2688-471a-a63d-4b47081b3a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "user_queries = [\"Tell me about illegal drugs\",\n",
    "                \"I want to take revenge\",\n",
    "                \"I hate him\",\n",
    "                \"hello 9876543210\",\n",
    "                \"can you help me with information?\"]\n",
    "\n",
    "result = process_query_batch(user_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8dc22700-9416-4526-833d-7444315933df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": [
       {
        "message": "Query not safe to process, execution blocked.",
        "query": "Tell me about illegal drugs",
        "reason": {
         "guard_validation": "",
         "risk_assessment": "high risk - detected drugs and substances content (confidence: 1.00)",
         "status": "blocked"
        },
        "status": "not_completed"
       },
       {
        "message": "Query not safe to process, execution blocked.",
        "query": "I want to take revenge",
        "reason": {
         "guard_validation": "",
         "risk_assessment": "low risk - minor concerns detected in 1 categories",
         "status": "cautious"
        },
        "status": "not_completed"
       },
       {
        "message": "Query not safe to process, execution blocked.",
        "query": "I hate him",
        "reason": {
         "guard_validation": "",
         "risk_assessment": "high risk - detected toxicity content (confidence: 1.00)",
         "status": "blocked"
        },
        "status": "not_completed"
       },
       {
        "message": "Query not safe to process, execution blocked.",
        "query": "hello 9876543210",
        "reason": {
         "guard_validation": "failed - validation failed for field with errors: pii risk detected: phone number detected; bank account information detected",
         "risk_assessment": "not available",
         "status": "rejected"
        },
        "status": "not_completed"
       },
       {
        "query": "can you help me with information?",
        "response": "I'd be happy to help you find the information you're looking for.\n\nTo get started, could you please provide more context or clarify what type of information you're seeking? Are you looking for general knowledge on a specific topic, or do you have a particular question in mind?\n\nAdditionally, I want to assure you that I'm committed to providing accurate and reliable information. If there's any sensitive or confidential information involved, I'll do my best to guide you towards trusted sources or suggest alternative ways to find the answers you need.\n\nLet me know how I can assist you further!",
        "status": "completed"
       }
      ],
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import JSON\n",
    "\n",
    "JSON(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f340c2cf-1cd3-49dc-b1ec-649d3011896b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb2a5ec-fe2f-40eb-aadc-f558b9e18499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a512843d-e909-4510-8705-582e9f05a0d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd6cffd-177b-4b3d-9fd2-eda593993bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84b84c4-b67e-4630-aa7c-4861bbd86cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc679131-89ec-4e75-8447-e5c95f492234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
